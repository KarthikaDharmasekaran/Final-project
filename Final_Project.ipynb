{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7ba0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dcd8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('C:/Users/USER/Downloads/healthcare_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734159bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c38884",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd133aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0825c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts = df[\"Rating\"].value_counts().reset_index()\n",
    "df_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4a2d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154015e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aea2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b78dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_sentiment(Rating):\n",
    "    \n",
    "    if Rating==1 or Rating==2:\n",
    "        return -1 # negative sentiment\n",
    "    elif Rating==4 or Rating==5:\n",
    "        return 1 # positive sentiment\n",
    "    else:\n",
    "        return 0 # neutral sentiment\n",
    "\n",
    "df['Sentiment'] = df['Rating'].apply(create_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c96fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab3671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81645e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, how=\"any\", subset=None, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d341d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb4b47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c1ad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e328bca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Sentiment',data= df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1848edb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "    \"\"\" Return a cleaned version of text\n",
    "    \"\"\"\n",
    "    # Remove HTML markup\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    # Save emoticons for later appending\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    # Remove any non-word character and append the emoticons,\n",
    "    # removing the nose character for standarization. Convert to lower case\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-', ''))\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5440c67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def tokenizer_porter(text):\n",
    "    token = []\n",
    "    for word in text.split():\n",
    "        token.append(porter.stem(word))\n",
    "    \n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4f46ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model evaluvation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ca609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['Sentiment'] \n",
    "X = df['Review_Text']\n",
    "\n",
    "my_additional_stop_words = []\n",
    "\n",
    "#stop = text.ENGLISH_STOP_WORDS.union(my_additional_stop_words)\n",
    "from spacy.lang.de.stop_words import STOP_WORDS\n",
    "tfidf = TfidfVectorizer(stop_words=list(STOP_WORDS),\n",
    "                        tokenizer=tokenizer_porter,\n",
    "                        preprocessor=preprocessor)\n",
    "\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "# split the dataset in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.186, random_state=142)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815b5efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3061ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e56176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fddb8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Now apply those above metrics to evaluate your model\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "print('The accuracy score is:',accuracy_score(y_test,predictions))\n",
    "print('The confusion matrix is:','\\n',confusion_matrix(y_test,predictions))\n",
    "print('The classification report is:','\\n',classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae194f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f094274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b6b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f47bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_predictions = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The accuracy score is:',accuracy_score(y_test,dtc_predictions))\n",
    "print('The confusion matrix is:','\\n',confusion_matrix(y_test,dtc_predictions))\n",
    "print('The classification report is:','\\n',classification_report(y_test,dtc_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10989d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a112295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2762ae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e16b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff84804",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The accuracy score is:',accuracy_score(y_test,rfc_predictions))\n",
    "print('The confusion matrix is:','\\n',confusion_matrix(y_test,rfc_predictions))\n",
    "print('The classification report is:','\\n',classification_report(y_test,rfc_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175a3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-fold cross validation should be used to tune the model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "n = [1 ,5 ,10, 15, 20, 30, 50, 100, 150, 200, 500]\n",
    "val_results = []\n",
    "\n",
    "for i in n:\n",
    "    clf = RandomForestClassifier(n_estimators=i)\n",
    "    val_results.append(cross_val_score(clf, X_train, y_train,cv=9).mean())\n",
    "    \n",
    "plt.scatter(n, val_results)\n",
    "print(val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba477c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rfc = RandomForestClassifier(n_estimators=600)\n",
    "\n",
    "final_rfc.fit(X_train, y_train)\n",
    "final_predictions = final_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675faf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The accuracy score is:',accuracy_score(y_test,final_predictions))\n",
    "print('The confusion matrix is:','\\n',confusion_matrix(y_test,final_predictions))\n",
    "print('The classification report is:','\\n',classification_report(y_test,final_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705affc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29940a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f495730",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tuning using K-fold Cross Validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "val_error_rate = []\n",
    "neighbors_range = range(1,500,5)\n",
    "\n",
    "for i in neighbors_range:\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    \n",
    "    val_error = 1 - cross_val_score(knn, X_train, y_train,cv=5).mean()\n",
    "    val_error_rate.append(val_error)\n",
    "\n",
    "# Plot settings\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(neighbors_range, val_error_rate, color='orange', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='black', markersize=5, label='Validation Error')\n",
    "plt.xticks(np.arange(neighbors_range.start, neighbors_range.stop, neighbors_range.step), rotation=60)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title('Validation Error vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Validation Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10aa4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = neighbors_range[val_error_rate.index(min(val_error_rate))]\n",
    "best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ea9a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_predictions = knn.predict(X_test)\n",
    "\n",
    "print('The accuracy score is:',accuracy_score(y_test,knn_predictions))\n",
    "print('The classification report is:','\\n',classification_report(y_test,knn_predictions))\n",
    "\n",
    "matrix=confusion_matrix(y_test,knn_predictions)\n",
    "plt.figure(figsize = (5,4))\n",
    "sns.heatmap(matrix, annot=True, fmt = '.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4aaccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "final_rfc = RandomForestClassifier(n_estimators=7)\n",
    "\n",
    "final_rfc.fit(X_train, y_train)\n",
    "final_predictions = final_rfc.predict(X_test)\n",
    "\n",
    "print('The accuracy score is:',accuracy_score(y_test,final_predictions))\n",
    "print('The confusion matrix is:','\\n',confusion_matrix(y_test,final_predictions))\n",
    "print('The classification report is:','\\n',classification_report(y_test,final_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ab80b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we can say that we almost have same number of reviews. That mean we have very good data.\n",
    "sns.barplot(data=df, x='Rating', y='Sentiment')\n",
    "plt.xlabel(\"Sentiment Type\");\n",
    "plt.ylabel(\"Total Count\");\n",
    "plt.title(\"Total Postive ,Negative & Neutral Reviews\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f35fd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x='Rating', y='Sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004eb374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50e69ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152f4d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "val_rate = []\n",
    "c_range =  range(1,200,20)\n",
    "\n",
    "for i in c_range:\n",
    "    \n",
    "    svm = SVC(C=i, kernel='linear')\n",
    "    \n",
    "    val_error = 1 - cross_val_score(svm, X_train, y_train,cv=9).mean()\n",
    "    val_rate.append(val_error)\n",
    "\n",
    "\n",
    "# Plot settings\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(c_range, val_rate, color='orange', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='black', markersize=5, label='Validation Error')\n",
    "\n",
    "plt.xticks(np.arange(c_range.start, c_range.stop, c_range.step), rotation=60)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title('Validation Error vs. C Value')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Validation Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47bb13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear',C=9).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c365f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74733954",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fdc564",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The accuracy score is:',accuracy_score(y_test, pred))\n",
    "print('The confusion matrix is:','\\n',confusion_matrix(y_test, pred))\n",
    "print('The classification report is:','\\n',classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182c13ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear',C=42).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a168d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e5fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752a7844",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The accuracy score is:',accuracy_score(y_test, pred))\n",
    "print('The confusion matrix is:','\\n',confusion_matrix(y_test, pred))\n",
    "print('The classification report is:','\\n',classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f91c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Reshape X_train, X_test by fit_transform\n",
    "X_new_train = SelectKBest(chi2, k=45000).fit_transform(X_train, y_train)\n",
    "X_new_test = SelectKBest(chi2, k=45000).fit_transform(X_test, y_test)\n",
    "\n",
    "# Build Logistic Regression Model and check accuracy\n",
    "clf.fit(X_new_train, y_train)\n",
    "\n",
    "new_predictions = clf.predict(X_new_test)\n",
    "\n",
    "print('The accuracy score is:',accuracy_score(y_test,new_predictions))\n",
    "print('The confusion matrix is:','\\n',confusion_matrix(y_test,new_predictions))\n",
    "print('The classification report is:','\\n',classification_report(y_test,new_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1958425a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0df521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
